{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Pre-Built & Custom AI Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will integrate with the Computer Vision API and the Text Analytics API to augment the claims processing capabilities. In the end, you will integrate the API calls to the summarizer and classifier services that your deployed and produce a finished claim report that shows all of the processing applied to the claim text and claim image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Caption & Tag with the Computer Vision API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell bellow, provided the key to your Computer Vision API and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = \"9fdb8d2ec4e24a699f9a46224a3b0fc9\"\n",
    "assert subscription_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the endpoint to the Computer Vision API by running the following cell. Notice the last path segment is analyzy, which indicates you will use the analyze feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_base_url = \"https://westus2.api.cognitive.microsoft.com/vision/v1.0/\"\n",
    "vision_analyze_url = vision_base_url + \"analyze\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a list of sample images found after performing a simple web search. Feel free to substitute in URL's to the image of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fender_bender = \"http://ford-life.com/wp-content/uploads/2012/03/Fender-Bender-image.jpg\"\n",
    "damaged_house = \"https://c2.staticflickr.com/8/7342/10983313185_0589b74946_z.jpg\"\n",
    "police_car = \"https://localtvwnep.files.wordpress.com/2015/11/fender-bender.jpeg?quality=85&strip=all\"\n",
    "car_with_text = \"https://static.buildasign.com/cmsimages/bas-vinyl-lettering-splash-01.png?v=4D66584B51394A676D68773D\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list of images above, select one and assign it to image_url for further processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = police_car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to preview the image you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://localtvwnep.files.wordpress.com/2015/11/fender-bender.jpeg?quality=85&strip=all\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= image_url, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell builds the HTTP request to make against the Computer Vision API. \n",
    "\n",
    "Run the following cell to retrieve the caption and tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': [{'name': 'others_', 'score': 0.39453125},\n",
       "  {'name': 'trans_car', 'score': 0.44140625}],\n",
       " 'color': {'accentColor': '895D42',\n",
       "  'dominantColorBackground': 'White',\n",
       "  'dominantColorForeground': 'White',\n",
       "  'dominantColors': ['White'],\n",
       "  'isBwImg': False},\n",
       " 'description': {'captions': [{'confidence': 0.9485308427051494,\n",
       "    'text': 'a truck is parked on the side of a road'}],\n",
       "  'tags': ['outdoor',\n",
       "   'road',\n",
       "   'truck',\n",
       "   'car',\n",
       "   'parked',\n",
       "   'street',\n",
       "   'large',\n",
       "   'sitting',\n",
       "   'side',\n",
       "   'man',\n",
       "   'bus',\n",
       "   'white',\n",
       "   'black',\n",
       "   'standing',\n",
       "   'riding',\n",
       "   'city',\n",
       "   'driving',\n",
       "   'red',\n",
       "   'blue',\n",
       "   'people',\n",
       "   'traffic']},\n",
       " 'metadata': {'format': 'Jpeg', 'height': 1080, 'width': 1920},\n",
       " 'requestId': '9abe3c92-4c14-42e7-84c3-f87964c8da62',\n",
       " 'tags': [{'confidence': 0.9950141310691833, 'name': 'outdoor'},\n",
       "  {'confidence': 0.9936342239379883, 'name': 'road'},\n",
       "  {'confidence': 0.981715738773346, 'name': 'truck'},\n",
       "  {'confidence': 0.749627411365509, 'name': 'transport'},\n",
       "  {'confidence': 0.16133838891983032, 'name': 'trailer'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "headers  = {'Ocp-Apim-Subscription-Key': subscription_key }\n",
    "params   = {'visualFeatures': 'Categories,Description,Tags,Color'}\n",
    "data     = {'url': image_url}\n",
    "response = requests.post(vision_analyze_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "analysis = response.json()\n",
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the above output, the result is a nested document structure. Run the following cells to pull out the caption and top 3 tag results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A truck is parked on the side of a road'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outdoor', 'road', 'truck']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topTags = analysis[\"description\"][\"tags\"][0:3]\n",
    "topTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Performing OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform OCR with the Computer Vision service, you need to target the OCR endpoint. \n",
    "\n",
    "Run the following cell to construct the right URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_ocr_url = vision_base_url + \"ocr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, invoke the OCR endpoint with the following code and examine the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'language': 'en',\n",
       " 'orientation': 'Up',\n",
       " 'regions': [{'boundingBox': '365,127,937,78',\n",
       "   'lines': [{'boundingBox': '1028,127,274,49',\n",
       "     'words': [{'boundingBox': '1028,141,184,35', 'text': 'TAYLOR'},\n",
       "      {'boundingBox': '1228,127,74,42', 'text': 'Sip'}]},\n",
       "    {'boundingBox': '365,171,318,34',\n",
       "     'words': [{'boundingBox': '365,171,318,34', 'text': 'EMERGENCY'}]}]}],\n",
       " 'textAngle': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers  = {'Ocp-Apim-Subscription-Key': subscription_key }\n",
    "params   = {}\n",
    "data     = {'url': image_url}\n",
    "response = requests.post(vision_ocr_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "ocr_analysis = response.json()\n",
    "ocr_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided the following code for you to extract the text as a flat array from the results.\n",
    "\n",
    "Run the following cell to extract the text items from the results document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TAYLOR', 'Sip', 'EMERGENCY']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "flatten = lambda x: list(itertools.chain.from_iterable(x))\n",
    "words_list = [[ [w['text'] for w in line['words']]  for line in d['lines']] for d in ocr_analysis['regions']]\n",
    "words_list = flatten(flatten(words_list))\n",
    "print(list(words_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Performing Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis is performed using the Text Analytics API. \n",
    "\n",
    "Update the following cell with the key to your instance of the Text Analytics API and run the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_analytics_subscription_key = \"a967cecfbd6e403d974a75f8a00b8bdb\"\n",
    "assert text_analytics_subscription_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the following cell with the correct base URL for your deployed instance of the Text Analytics API and run the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_analytics_base_url = \"https://westus2.api.cognitive.microsoft.com/text/analytics/v2.0/\"\n",
    "sentiment_api_url = text_analytics_base_url + \"sentiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell has a set of example claims you can use to test the measurement sentiment. \n",
    "\n",
    "Run the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sent = \"\"\"We are just devastated and emotionally drained. \n",
    "The roof was torn off of our car, and to make matters\n",
    "worse my daughter's favorite teddy bear was impaled on the street lamp.\"\"\"\n",
    "pos_sent = \"\"\"We are just happy the damaage was mininmal and that everyone is safe. \n",
    "We are thankful for your support.\"\"\"\n",
    "neutral_sent = \"\"\"I crashed my car.\"\"\"\n",
    "long_claim = \"\"\"\n",
    "I was driving down El Camino and stopped at a red light.\n",
    "It was about 3pm in the afternoon.  \n",
    "The sun was bright and shining just behind the stoplight.\n",
    "This made it hard to see the lights.\n",
    "There was a car on my left in the left turn lane.\n",
    "A few moments later another car, a black sedan pulled up behind me. \n",
    "When the left turn light changed green, the black sedan hit me thinking \n",
    "that the light had changed for us, but I had not moved because the light \n",
    "was still red.\n",
    "After hitting my car, the black sedan backed up and then sped past me.\n",
    "I did manage to catch its license plate. \n",
    "The license plate of the black sedan was ABC123. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above list of claims, select one and assign its variable to claim_text to be used in the call to the Text Analytics API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_text = long_claim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API requires you to submit a document of the following form. \n",
    "\n",
    "Run the cell to build the request document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {'documents' : [\n",
    "    {'id': '1', 'language': 'en', 'text': claim_text}\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now invoke the Text Analytics API and observe the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': [{'id': '1', 'score': 0.5}], 'errors': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers   = {\"Ocp-Apim-Subscription-Key\": text_analytics_subscription_key}\n",
    "response  = requests.post(sentiment_api_url, headers=headers, json=documents)\n",
    "sentiments = response.json()\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse out the sentiment score from the response, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sentiments['documents'][0]['score']\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can provide a human-friendly interpretation on this score by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_interpretation = \"neutral\"\n",
    "if (score < 0.45): \n",
    "    score_interpretation = \"negative\"\n",
    "elif (score >= 0.55):\n",
    "    score_interpretation = \"positive\"\n",
    "score_interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Invoking the Azure ML Deployed Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to define a method that will be used to invoke your classifier and summarizer methods deployed using Azure Machine Learning services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_service(ml_service_key, ml_service_scoring_endpoint, ml_service_input):\n",
    "    headers   = {\"Authorization\": \"Bearer \" + ml_service_key}\n",
    "    response  = requests.post(ml_service_scoring_endpoint, headers=headers, json=ml_service_input)\n",
    "    result = response.json()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the classifier invocation with the key and endpoint as appropriate to your deployed instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_service_key = \"MdhGeZiTO3Abu8nv5n2V1LV8FFchjKgO\"\n",
    "classifier_service_scoring_endpoint = \"http://104.46.119.173/api/v1/service/claimclassifier/score\"\n",
    "classifier_service_input = claim_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the classifier and observe the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_result = invoke_service(classifier_service_key, classifier_service_scoring_endpoint, classifier_service_input)\n",
    "classifier_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, configure the key and scoring endpoint as appropriate to your summarizer service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_service_key = \"7xUzUqcfUYmigIBXRjYP6cN0gfP6j9Ng\"\n",
    "summarizer_service_scoring_endpoint = \"http://104.46.119.173/api/v1/service/summarizer/score\"\n",
    "summarizer_service_input = claim_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the summarizer service and observe the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sun was bright and shining just behind the stoplight.This made it hard to see the lights.There was a car on my left in the left turn lane.A few moments later another car, a black sedan pulled up behind me.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_result = invoke_service(summarizer_service_key, summarizer_service_scoring_endpoint, summarizer_service_input)\n",
    "summarizer_result =  summarizer_result[0].replace(\"\\\\n\", \"\").strip() if len(summarizer_result) > 0 else \"N/A\"\n",
    "summarizer_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 -  Summarizing the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final task, you pull together all of the pieces to display the results of your AI based processing.\n",
    "\n",
    "Run the following cell and examine the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div><b>Claim Summary</b></div>\n",
       "<div>Caption: A truck is parked on the side of a road</div>\n",
       "<div>Tags: outdoor road truck</div>\n",
       "<div>Text in Image: TAYLOR Sip EMERGENCY</div>\n",
       "<div>Sentiment: neutral</div>\n",
       "<div><img src='https://localtvwnep.files.wordpress.com/2015/11/fender-bender.jpeg?quality=85&strip=all' width='200px'></div>\n",
       "<div>Summary: </div>\n",
       "<div><pre>The sun was bright and shining just behind the stoplight.This made it hard to see the lights.There was a car on my left in the left turn lane.A few moments later another car, a black sedan pulled up behind me. </pre></div>\n",
       "<div>&nbsp;</div>\n",
       "<div>Claim:</div>\n",
       "<div>\n",
       "I was driving down El Camino and stopped at a red light.\n",
       "It was about 3pm in the afternoon.  \n",
       "The sun was bright and shining just behind the stoplight.\n",
       "This made it hard to see the lights.\n",
       "There was a car on my left in the left turn lane.\n",
       "A few moments later another car, a black sedan pulled up behind me. \n",
       "When the left turn light changed green, the black sedan hit me thinking \n",
       "that the light had changed for us, but I had not moved because the light \n",
       "was still red.\n",
       "After hitting my car, the black sedan backed up and then sped past me.\n",
       "I did manage to catch its license plate. \n",
       "The license plate of the black sedan was ABC123. \n",
       "</div>\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython.display\n",
    "\n",
    "displayTemplate = \"\"\"\n",
    "<div><b>Claim Summary</b></div>\n",
    "<div>Caption: {}</div>\n",
    "<div>Tags: {}</div>\n",
    "<div>Text in Image: {}</div>\n",
    "<div>Sentiment: {}</div>\n",
    "<div><img src='{}' width='200px'></div>\n",
    "<div>Summary: </div>\n",
    "<div><pre>{} </pre></div>\n",
    "<div>&nbsp;</div>\n",
    "<div>Claim:</div>\n",
    "<div>{}</div>\n",
    "\n",
    "\"\"\"\n",
    "displayTemplate = displayTemplate.format(caption, ' '.join(topTags), ' '.join(words_list), \n",
    "                                         score_interpretation, image_url, summarizer_result, \n",
    "                                         claim_text)\n",
    "IPython.display.display_html(displayTemplate, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
